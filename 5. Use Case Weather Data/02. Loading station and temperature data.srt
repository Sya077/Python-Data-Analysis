1
00:00:00,05 --> 00:00:01,08
- [Instructor] In this chapter,

2
00:00:01,08 --> 00:00:04,07
we download several data files from the web.

3
00:00:04,07 --> 00:00:07,03
However, all the files that we analyze

4
00:00:07,03 --> 00:00:10,01
are also included in your exercise files,

5
00:00:10,01 --> 00:00:12,06
in case they became unavailable online,

6
00:00:12,06 --> 00:00:16,07
or you're unable to download them for any other reason.

7
00:00:16,07 --> 00:00:18,05
And before we load the data itself,

8
00:00:18,05 --> 00:00:20,01
it's also a good idea

9
00:00:20,01 --> 00:00:23,04
to start by looking at it's documentation.

10
00:00:23,04 --> 00:00:27,02
Browsing through the file listing at the NOAA website,

11
00:00:27,02 --> 00:00:30,07
we see a README file, and we start there.

12
00:00:30,07 --> 00:00:32,09
Instead of clicking on that link in our browser,

13
00:00:32,09 --> 00:00:35,06
let's use Python to download the file.

14
00:00:35,06 --> 00:00:37,08
There are several Python modules we could use,

15
00:00:37,08 --> 00:00:39,04
but for a simple download,

16
00:00:39,04 --> 00:00:41,08
the standard library module, urllib,

17
00:00:41,08 --> 00:00:45,04
is quite appropriate.

18
00:00:45,04 --> 00:00:49,05
urllib.request.urlretrieve needs the URL

19
00:00:49,05 --> 00:00:52,04
and the name of a local file.

20
00:00:52,04 --> 00:00:53,07
It's done already.

21
00:00:53,07 --> 00:00:57,01
We can use the Jupyter Notebook

22
00:00:57,01 --> 00:01:02,04
to look at the README file, by clicking on it.

23
00:01:02,04 --> 00:01:05,09
We see that it describes the contents of the directory,

24
00:01:05,09 --> 00:01:10,09
the format of DLY data files,

25
00:01:10,09 --> 00:01:13,04
which contain data for a single station,

26
00:01:13,04 --> 00:01:17,02
and are formatted with fixed-width columns.

27
00:01:17,02 --> 00:01:20,09
And the format of a file, GHCND stations,

28
00:01:20,09 --> 00:01:24,04
thank you, says the location, elevation, and ID

29
00:01:24,04 --> 00:01:27,01
for each station in the network.

30
00:01:27,01 --> 00:01:28,08
That's where we need to start,

31
00:01:28,08 --> 00:01:34,05
so we download that file with urllib.

32
00:01:34,05 --> 00:01:37,00
I've copied the description of the format

33
00:01:37,00 --> 00:01:39,02
into a text field in this Notebook,

34
00:01:39,02 --> 00:01:42,02
for our reference.

35
00:01:42,02 --> 00:01:45,06
To load a fixed-width text file, such as this,

36
00:01:45,06 --> 00:01:48,05
we can use NumPy genfromtxt.

37
00:01:48,05 --> 00:01:51,06
It needs rather precise information.

38
00:01:51,06 --> 00:01:54,02
We specify the width of each field

39
00:01:54,02 --> 00:01:57,00
in the parameter delimiter.

40
00:01:57,00 --> 00:02:00,00
We can derive the widths from the table above,

41
00:02:00,00 --> 00:02:01,04
or we need to increase them

42
00:02:01,04 --> 00:02:04,07
to include the spaces between the columns.

43
00:02:04,07 --> 00:02:06,04
Next, we provide the name,

44
00:02:06,04 --> 00:02:09,04
a descriptive name for each column.

45
00:02:09,04 --> 00:02:11,07
And we specify the dtype,

46
00:02:11,07 --> 00:02:14,08
the NumPy data type for each column.

47
00:02:14,08 --> 00:02:16,03
For the first field, for instance,

48
00:02:16,03 --> 00:02:19,04
we need a string of 11 characters.

49
00:02:19,04 --> 00:02:21,09
Then, we have three floats,

50
00:02:21,09 --> 00:02:25,05
and a few more strings of various lengths.

51
00:02:25,05 --> 00:02:27,06
And last, we'll tell NumPy

52
00:02:27,06 --> 00:02:30,02
to remove all the leading and trailing spaces

53
00:02:30,02 --> 00:02:35,00
from all the strings it parses.

54
00:02:35,00 --> 00:02:37,02
There result is a NumPy record array

55
00:02:37,02 --> 00:02:42,05
with more than a hundred thousand entries.

56
00:02:42,05 --> 00:02:45,01
Thankfully, Jupyter chooses to show us only a few lines

57
00:02:45,01 --> 00:02:47,05
at the top and the bottom.

58
00:02:47,05 --> 00:02:50,05
By plotting longitude against latitude,

59
00:02:50,05 --> 00:02:53,01
we get an idea of the impressive global coverage

60
00:02:53,01 --> 00:02:55,02
of the database.

61
00:02:55,02 --> 00:02:57,06
We need to make the dots small,

62
00:02:57,06 --> 00:03:01,07
so that they're not too crowded.

63
00:03:01,07 --> 00:03:04,00
Even so, the US and Europe are basically

64
00:03:04,00 --> 00:03:07,00
just solid masses of ink.

65
00:03:07,00 --> 00:03:09,01
How about stations in California?

66
00:03:09,01 --> 00:03:12,08
We can use fancy indexing with a Boolean expression,

67
00:03:12,08 --> 00:03:17,00
stations state equals equals CA

68
00:03:17,00 --> 00:03:21,01
to downselect our dataset.

69
00:03:21,01 --> 00:03:24,00
Coverage is still impressive.

70
00:03:24,00 --> 00:03:27,00
What if we need a specific station?

71
00:03:27,00 --> 00:03:30,06
Fancy indexing again comes to the rescue.

72
00:03:30,06 --> 00:03:31,09
We select all stations,

73
00:03:31,09 --> 00:03:37,07
for which it is true that the name field equals 'Pasadena'.

74
00:03:37,07 --> 00:03:39,03
We find one.

75
00:03:39,03 --> 00:03:42,05
If we want all stations that start with a given string,

76
00:03:42,05 --> 00:03:45,01
the syntax would be more esoteric.

77
00:03:45,01 --> 00:03:48,08
What np.char.find does,

78
00:03:48,08 --> 00:03:53,01
is to return the index at which a certain substring,

79
00:03:53,01 --> 00:03:54,05
'Pasadena' in this case,

80
00:03:54,05 --> 00:03:56,01
appears in the field,

81
00:03:56,01 --> 00:03:59,09
or minus one if the substring is not there.

82
00:03:59,09 --> 00:04:01,09
If we required the index to be zero,

83
00:04:01,09 --> 00:04:03,02
that's the same as saying

84
00:04:03,02 --> 00:04:07,01
that the station name begins with 'Pasadena'.

85
00:04:07,01 --> 00:04:09,05
So, we see that there are several stations,

86
00:04:09,05 --> 00:04:13,08
a few of them in Pasadena, Texas and Pasadena, Maryland.

87
00:04:13,08 --> 00:04:15,00
Only one, however,

88
00:04:15,00 --> 00:04:19,05
is in the quality-controlled HCN network.

89
00:04:19,05 --> 00:04:22,03
Let's get that one.

90
00:04:22,03 --> 00:04:25,03
I've built this URL by looking at the structure

91
00:04:25,03 --> 00:04:28,04
of the directories on the website.

92
00:04:28,04 --> 00:04:36,07
You see that it ends in Pasadena's ID, USC00046719.dly.

93
00:04:36,07 --> 00:04:42,05
Locally, we'll download to the file Pasadena.dly.

94
00:04:42,05 --> 00:04:44,01
Let's look at that file.

95
00:04:44,01 --> 00:04:48,05
Again, with Jupyter Notebook.

96
00:04:48,05 --> 00:04:51,01
It's quite messy, but we recognize the station ID

97
00:04:51,01 --> 00:04:52,06
in the beginning of each line,

98
00:04:52,06 --> 00:04:55,01
followed by year and month.

99
00:04:55,01 --> 00:04:57,04
Here, we are in 1918.

100
00:04:57,04 --> 00:05:00,02
The name of an element, such as TMAX,

101
00:05:00,02 --> 00:05:04,06
and 31 data points, one for each day of the month.

102
00:05:04,06 --> 00:05:06,03
Each data point itself,

103
00:05:06,03 --> 00:05:10,00
consists of the value and three flags.

104
00:05:10,00 --> 00:05:11,09
We could use genfromtxt again,

105
00:05:11,09 --> 00:05:13,07
but it's going to take us a while,

106
00:05:13,07 --> 00:05:17,07
so, I prepared a small module for you, getweather.py,

107
00:05:17,07 --> 00:05:19,09
that takes care of parsing the file

108
00:05:19,09 --> 00:05:23,04
and returning consecutive daily values for a year.

109
00:05:23,04 --> 00:05:26,05
The module uses Pandas to clean and reformat data,

110
00:05:26,05 --> 00:05:30,03
but returns it as a pure NumPy array.

111
00:05:30,03 --> 00:05:33,03
After you've learned about Pandas later in this course,

112
00:05:33,03 --> 00:05:36,01
I encourage you to go look at getweather.py

113
00:05:36,01 --> 00:05:38,04
and see what I did there.

114
00:05:38,04 --> 00:05:41,07
We import the module

115
00:05:41,07 --> 00:05:46,08
and then we look at the help, known as docstring.

116
00:05:46,08 --> 00:05:49,01
This function does what I described,

117
00:05:49,01 --> 00:05:53,05
returning data for one year, for one station.

118
00:05:53,05 --> 00:05:57,02
Let's try it out on Pasadena.

119
00:05:57,02 --> 00:06:02,02
We request both TMIN and TMAX for year 2000.

120
00:06:02,02 --> 00:06:03,06
Some measurements are missing,

121
00:06:03,06 --> 00:06:08,02
and they are here represented as 'nan', nan, not a number.

122
00:06:08,02 --> 00:06:09,09
This function would be a great foundation

123
00:06:09,09 --> 00:06:12,00
for our work in the next few videos.

